# 第一部分 — 视觉与生成大模型导论

本部分概述视觉理解与生成领域中的基础概念、模型范式与迁移学习方法。目标是帮助读者从传统任务范式过渡到以大模型（如CLIP、GAN、扩散模型、3D与视频大模型）为核心的研究与工程实践。

**学习目标**

- 理解视觉理解与生成的主要任务范式与代表模型。
- 掌握迁移学习与微调在视觉任务中的常见策略。
- 了解视觉理解、生成与三维/视频大模型的融合趋势与应用场景。

本部分包含五章，按由浅入深的顺序组织：

- 第一章：视觉理解任务范式的迁移 — 介绍传统视觉理解任务、CLIP 等视觉-文本大模型、迁移学习与微调方法，以及将 LLM 与视觉模块结合的思路。[阅读第一章](chapter1.md)
- 第二章：视觉生成任务范式的迁移 — 覆盖 GAN、扩散模型与生成模型的迁移学习实践，讨论生成任务中的训练与评估要点。[阅读第二章](chapter2.md)
- 第三章：视觉理解与生成任务范式的融合 — 探讨理解与生成任务的协同、代表性融合模型与在融合场景中的迁移策略。[阅读第三章](chapter3.md)
- 第四章：3D 基础大模型 — 介绍 3D 表示与基础大模型、典型应用（重建、渲染、仿真）及其训练与迁移方法。[阅读第四章](chapter4.md)
- 第五章：视频生成大模型 — 讲解视频生成的模型架构、训练策略与实际应用案例，及对计算与数据的挑战分析。[阅读第五章](chapter5.md)

**如何阅读本部分**

- 若你关注模型原理与训练方法，建议按章顺序阅读并关注每章的示例代码与实践提示。
- 若你希望快速上手应用场景，可先阅读第二章与第五章，了解生成模型与视频模型的使用要点，再回到第一章与第三章补充理解。

欢迎在每章末尾查看“本章小结”与参考实现代码片段，以便将理论知识转为工程实践。